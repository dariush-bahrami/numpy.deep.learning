{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepLearningNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc-autonumbering": true
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEVWWGAytvXA"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_adi4DUtvXD"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import PIL\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import copy\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBeRwmdutvXO"
      },
      "source": [
        "# Structure Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrEsUnixtvXQ"
      },
      "source": [
        "## Activation Functions Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icI3PddDtvXR"
      },
      "source": [
        "def sigmoid(z):\n",
        "    # negative_overflow = np.where(z<=-709, 0, 0)\n",
        "    okay_range = np.where((-709<z)&(z<709), 1/(1 + np.exp(-z)), 0)\n",
        "    positive_overflow = np.where(z>=709, 1, 0)\n",
        "    return okay_range + positive_overflow\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "    return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "\n",
        "def relu(z, leak_grad=0):\n",
        "    return np.maximum(leak_grad*z, z)\n",
        "\n",
        "\n",
        "def relu_derivative(z, leak_grad=0):\n",
        "    return np.where(z <= 0, leak_grad, 1)\n",
        "\n",
        "\n",
        "def tanh(z):\n",
        "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
        "\n",
        "\n",
        "def tanh_derivative(z):\n",
        "    return 1 - tanh(z)**2\n",
        "\n",
        "\n",
        "def softmax(Z, epsilon=1e-8):\n",
        "    Z = Z - np.max(Z)\n",
        "    exp_Z = np.exp(Z)\n",
        "    return exp_Z / (np.sum(exp_Z, axis=0)+epsilon)\n",
        "\n",
        "# def softmax_derivative(Z):\n",
        "#     return 1\n",
        "\n",
        "def identity(Z):\n",
        "    return Z\n",
        "\n",
        "def identity_derivative(Z):\n",
        "    return 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToG5-ziotvXY"
      },
      "source": [
        "activation_functions_dict = {'sigmoid': (sigmoid, sigmoid_derivative),\n",
        "                             'relu': (relu, relu_derivative),\n",
        "                             'tanh': (tanh, tanh_derivative),\n",
        "                             'softmax': (softmax, None),\n",
        "                             'identity': (identity, identity_derivative)}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A53MQON8tvXh"
      },
      "source": [
        "## Layer Namespace Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aVttHGxtvXi"
      },
      "source": [
        "class LayerNamespace(object):\n",
        "    pass"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CotRqlYStvXo"
      },
      "source": [
        "## Structure Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVGGGu36tvXp"
      },
      "source": [
        "class ModelStructure(object):\n",
        "    def __init__(self):\n",
        "        self.__layers = []\n",
        "\n",
        "    def add_input_layer(self, input_features: int):\n",
        "        assert len(self.__layers) == 0, 'Add input layer before other layers'\n",
        "        assert type(input_features) == int, 'Enter integer number'\n",
        "        layer_0 = LayerNamespace()\n",
        "        layer_0.units_number = input_features\n",
        "        self.__layers.append(layer_0)\n",
        "\n",
        "    def add_layer(self, units_number: int, activation_function_name='identity',\n",
        "                  keep_prob=1):\n",
        "        assert type(units_number) == int, 'Enter integer number'\n",
        "        assert len(self.__layers) > 0, 'First add input layer'\n",
        "\n",
        "        try:\n",
        "            layer = LayerNamespace()\n",
        "            valid_key = activation_function_name.lower()\n",
        "            layer.activation_function = activation_functions_dict[valid_key][0]\n",
        "            layer.activation_function_derivative = activation_functions_dict[valid_key][1]\n",
        "            layer.units_number = units_number\n",
        "            layer.keep_prob = keep_prob\n",
        "            self.__layers.append(layer)\n",
        "        except KeyError as error:\n",
        "            message = 'Valid activation functions: '\n",
        "            message += ', '.join(activation_functions_dict.keys())\n",
        "            raise KeyError(f'{error} ({message})')\n",
        "\n",
        "        return True\n",
        "\n",
        "    @property\n",
        "    def layers(self):\n",
        "        assert len(self.__layers) > 1, 'At least nsert one layer'\n",
        "        return self.__layers\n",
        "\n",
        "    def summary(self):\n",
        "        print(f'Input Features: {self.layers[0].units_number}')\n",
        "        total_parameters = 0\n",
        "        pre_units = self.layers[0].units_number\n",
        "        for i, layer in enumerate(self.layers[1:]):\n",
        "            weights = layer.units_number * pre_units\n",
        "            biases = layer.units_number\n",
        "            message_parts = [f'Layer #{i+1}:',\n",
        "                             f'{layer.units_number}',\n",
        "                             f'{layer.activation_function.__name__}',\n",
        "                             f'units with {weights} weights and',\n",
        "                             f'{biases} biases']\n",
        "            print(' '.join(message_parts))\n",
        "            pre_units = layer.units_number\n",
        "            total_parameters += (weights+biases)\n",
        "        print(f'Total Parameters: {total_parameters}')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-RlP8zmtvX-"
      },
      "source": [
        "# Computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOIA9vhitvX_"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMwEotMQDRig"
      },
      "source": [
        "### Initializer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQdsZ1fytvYA"
      },
      "source": [
        "def initialize(layers: list):\n",
        "    result = []\n",
        "    previous_layer = layers[0]\n",
        "    for layer in layers[1:]:\n",
        "        shape = (layer.units_number,\n",
        "                 previous_layer.units_number)\n",
        "        # On weight initialization in deep neural networks\n",
        "        scale_dict = {'relu': np.sqrt(2/shape[1]),\n",
        "                      'tanh': np.sqrt(1/shape[1]),\n",
        "                      'sigmoid': np.sqrt((3.6**2)/shape[1]),\n",
        "                      'softmax': np.sqrt(2/shape[1]),\n",
        "                      'identity': np.sqrt(2/shape[1])}\n",
        "        func_name = layer.activation_function.__name__\n",
        "        layer.W = np.random.randn(\n",
        "            shape[0], shape[1]) * scale_dict[func_name]\n",
        "\n",
        "        layer.b = np.zeros((shape[0], 1))\n",
        "        result.append(layer)\n",
        "        previous_layer = layer\n",
        "    return result"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW3IOak9DRiy"
      },
      "source": [
        "### Mini Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vku6MRgGDRi0"
      },
      "source": [
        "def mini_batch_generator(x: np.ndarray, y: np.ndarray, batch_size: int):\n",
        "    assert x.shape[1] == y.shape[1]\n",
        "    m = x.shape[1]\n",
        "    random_indice = np.random.permutation(m)\n",
        "    shuffled_x = x[:, random_indice]\n",
        "    shuffled_y = y[:, random_indice]\n",
        "\n",
        "    div = divmod(m, batch_size)\n",
        "    for i in range(div[0]):\n",
        "        x_mini_batch = shuffled_x[:, i*batch_size:(i+1)*batch_size]\n",
        "        x_mini_batch = x_mini_batch.reshape(x.shape[0], batch_size)\n",
        "\n",
        "        y_mini_batch = shuffled_y[:, i*batch_size:(i+1)*batch_size]\n",
        "        y_mini_batch = y_mini_batch.reshape(y.shape[0], batch_size)\n",
        "\n",
        "        yield x_mini_batch, y_mini_batch\n",
        "\n",
        "    if div[1]:\n",
        "        x_mini_batch = shuffled_x[:, div[0]*batch_size:]\n",
        "        x_mini_batch = x_mini_batch.reshape(x.shape[0], div[1])\n",
        "\n",
        "        y_mini_batch = shuffled_y[:, div[0]*batch_size:]\n",
        "        y_mini_batch = y_mini_batch.reshape(y.shape[0], div[1])\n",
        "\n",
        "        yield x_mini_batch, y_mini_batch"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onpcFF8tDRi7"
      },
      "source": [
        "### Metric Calculators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiQc8dw6DRi8"
      },
      "source": [
        " def get_predict_function(apply_softmax=True):   \n",
        " \n",
        "    def predict(model_output):\n",
        "        prediction = np.where(model_output > 0.5, 1, 0)\n",
        "        return prediction\n",
        "\n",
        "    def softmax_predict(Z):\n",
        "        A = softmax(Z)\n",
        "        return predict(A)\n",
        "\n",
        "    if apply_softmax:\n",
        "        return softmax_predict\n",
        "    else:\n",
        "        return predict\n",
        "\n",
        "def get_accuracy_function(binary=False):\n",
        "    def binary_accuracy(prediction, expected):\n",
        "        assert prediction.shape == expected.shape\n",
        "    #     assert prediction.shape[0] == 1\n",
        "        m = expected.shape[1]\n",
        "        accuracy = np.sum(prediction == expected)/m\n",
        "        return accuracy\n",
        "\n",
        "    def categorical_accuracy(prediction, expected):\n",
        "        assert prediction.shape == expected.shape\n",
        "        assert prediction.shape[0] != 1\n",
        "        m = expected.shape[1]\n",
        "        accuracy = np.sum(np.argmax(prediction, axis=0) == np.argmax(expected, axis=0))/m\n",
        "        return accuracy\n",
        "\n",
        "    if binary:\n",
        "        return binary_accuracy\n",
        "    else: \n",
        "        return categorical_accuracy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOjg-UbgDRjG"
      },
      "source": [
        "### Metric Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahvT82NiDRjJ"
      },
      "source": [
        "def print_metrics(interval=100):\n",
        "    def result_function(metrics):\n",
        "        epoch = metrics['total_trained_epochs']\n",
        "        if (epoch == 1) or (epoch % interval == 0):\n",
        "            cost = metrics['costs'][-1]\n",
        "            accuracy = metrics['accuracies'][-1]*100\n",
        "            message_parts = [f'Epoch #{epoch:0>4}',\n",
        "                             f'Cost: {cost:.4f}',\n",
        "                             f'Accuracy: {accuracy:.2f}%']\n",
        "\n",
        "            if metrics['validation_costs']:\n",
        "                validation_cost = metrics['validation_costs'][-1]\n",
        "                validation_accuracy = metrics['validation_accuracies'][-1]*100\n",
        "                message_parts.append(\n",
        "                    f'Validation Cost: {validation_cost:.4f}')\n",
        "                message_parts.append(\n",
        "                    f'Validation Accuracy: {validation_accuracy:.2f}%')\n",
        "\n",
        "            print(' | '.join(message_parts))\n",
        "    return result_function"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr2fr-aXtvYW"
      },
      "source": [
        "def plot_metrics(metrics: dict, interval=100):\n",
        "    cost = metrics['costs']\n",
        "    accuracy = metrics['accuracies']\n",
        "    validation_cost = metrics['validation_costs']\n",
        "    validation_accuracies = metrics['validation_accuracies']\n",
        "\n",
        "    fig, axes = plt.subplots(2, 1, constrained_layout=True)\n",
        "\n",
        "    axes[0].plot(cost[::interval], label='Training Cost')\n",
        "    axes[0].plot(validation_cost[::interval], label='Validation Cost')\n",
        "    axes[0].set_ylabel('epoch')\n",
        "    axes[0].set_ylabel('Cost')\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].plot(accuracy[::interval], label='Training Accuracy')\n",
        "    axes[1].plot(validation_accuracies[::interval],\n",
        "                 label='Validation Accuracy')\n",
        "    axes[1].set_ylabel('epoch')\n",
        "    axes[1].set_ylabel(f'Accuracy')\n",
        "    axes[1].legend()\n",
        "\n",
        "    # fig.tight_layout(pad=0, w_pad=0, h_pad=0)\n",
        "    fig.set_size_inches(12, 9)\n",
        "    plt.show()\n",
        "    return fig"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oJ69ziwDRjV"
      },
      "source": [
        "## Cost Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpgmiiX5DRjW"
      },
      "source": [
        "def get_cross_entropy_cost_function(binary=False):  \n",
        "    def binary_cross_entropy(Y, Y_hat, epsilon=1e-4):\n",
        "        assert Y.shape == Y_hat.shape, f'{Y.shape} != {Y_hat.shape}'\n",
        "        m = Y.shape[1]  # number of examples\n",
        "        cost = (-1/m) * (np.dot(Y, np.log(Y_hat+epsilon).T) +\n",
        "                        np.dot((1-Y), np.log(1-Y_hat+epsilon).T))\n",
        "        return cost.item()\n",
        "\n",
        "\n",
        "    def binary_cross_entropy_derivative(Y, Y_hat, epsilon=1e-4):\n",
        "        return ((1-Y)/(1-Y_hat+epsilon)) - (Y/(Y_hat+epsilon))\n",
        "\n",
        "    def softmax_crossentropy(Y, Y_hat, epsilon=1e-4):\n",
        "        assert Y.shape == Y_hat.shape, f'{Y.shape} != {Y_hat.shape}'\n",
        "        Y_hat = softmax(Y_hat)\n",
        "        m = Y.shape[1]\n",
        "        cost = 1/m * np.sum(-np.sum(Y*np.log(Y_hat+epsilon), axis=0))\n",
        "        return cost\n",
        "\n",
        "    def softmax_crossentropy_derivative(Y, Y_hat, epsilon=1e-7):\n",
        "        Y_hat = softmax(Y_hat)\n",
        "        return Y_hat-Y\n",
        "\n",
        "    if binary:\n",
        "        return binary_cross_entropy, binary_cross_entropy_derivative\n",
        "    else:\n",
        "        return softmax_crossentropy, softmax_crossentropy_derivative\n",
        "    \n",
        "def get_regularization_cost(layers: list, m: int, lambda_: float) -> float:\n",
        "    cost = 0\n",
        "    for layer in layers:\n",
        "        cost += np.sum(np.square(layer.W))\n",
        "    cost *= (1/m) * (lambda_/2)\n",
        "    return cost"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAIMipGtDRje"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrlo6Y05DRjg"
      },
      "source": [
        "### Optimizer Superclass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPUFSsZ5DRjh"
      },
      "source": [
        "class Optimizer(object):\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        pass\n",
        "    def update_parameters(self, layers: list):\n",
        "        pass\n",
        "    def update_optimizer(self, metrics: dict):\n",
        "        pass"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv5XsIRnDRjm"
      },
      "source": [
        "### Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK7NcD0EDRjn"
      },
      "source": [
        "class GradientDescent(Optimizer):\n",
        "    def __init__(self, learning_rate):\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.W = layer.W - self.learning_rate*layer.dW\n",
        "            layer.b = layer.b - self.learning_rate*layer.db\n",
        "        return True"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGAENBXUDRjv"
      },
      "source": [
        "### Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ogaM6P0DRjw"
      },
      "source": [
        "class Momentum(Optimizer):\n",
        "    def __init__(self, learning_rate, beta):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = beta\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.V_dW = np.zeros(layer.W.shape)\n",
        "            layer.V_db = np.zeros(layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:            \n",
        "            layer.V_dW = self.beta*layer.V_dW + (1-self.beta)*layer.dW\n",
        "            layer.V_db = self.beta*layer.V_db + (1-self.beta)*layer.db\n",
        "            \n",
        "            layer.W = layer.W - self.learning_rate*layer.V_dW\n",
        "            layer.b = layer.b - self.learning_rate*layer.V_db\n",
        "        return True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3fVRb6RDRj1"
      },
      "source": [
        "### RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O49wN-K5DRj2"
      },
      "source": [
        "class RMSprop(Optimizer):\n",
        "    def __init__(self, learning_rate, beta=0.9):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = beta\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.S_dW = np.zeros(layer.W.shape)\n",
        "            layer.S_db = np.zeros(layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:            \n",
        "            layer.S_dW = self.beta*layer.S_dW + (1-self.beta)*np.square(layer.dW)\n",
        "            layer.S_db = self.beta*layer.S_db + (1-self.beta)*np.square(layer.db)\n",
        "            \n",
        "            layer.W = layer.W - self.learning_rate*(layer.dW/(np.sqrt(layer.S_dW)+self.epsilon))\n",
        "            layer.b = layer.b - self.learning_rate*(layer.db/(np.sqrt(layer.S_db)+self.epsilon))\n",
        "        return True"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6othBMpDRj8"
      },
      "source": [
        "### Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPrPM09fDRj9"
      },
      "source": [
        "class Adam(Optimizer):\n",
        "    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "        self.epsilon = 1e-7\n",
        "        self.counter = 0\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        self.counter = 0\n",
        "        for layer in layers:\n",
        "            layer.V_dW = np.zeros(layer.W.shape)\n",
        "            layer.V_db = np.zeros(layer.b.shape)\n",
        "            layer.S_dW = np.zeros(layer.W.shape)\n",
        "            layer.S_db = np.zeros(layer.b.shape)\n",
        "            \n",
        "            layer.V_corrected_dW = np.zeros(layer.W.shape)\n",
        "            layer.V_corrected_db = np.zeros(layer.b.shape)\n",
        "            layer.S_corrected_dW = np.zeros(layer.W.shape)\n",
        "            layer.S_corrected_db = np.zeros(layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:            \n",
        "            layer.V_dW = self.beta_1*layer.V_dW + (1-self.beta_1)*layer.dW\n",
        "            layer.V_db = self.beta_1*layer.V_db + (1-self.beta_1)*layer.db\n",
        "            layer.S_dW = self.beta_2*layer.S_dW + (1-self.beta_2)*np.square(layer.dW)\n",
        "            layer.S_db = self.beta_2*layer.S_db + (1-self.beta_2)*np.square(layer.db)\n",
        "            \n",
        "            # Apply bias correction\n",
        "            momentum_correction = 1/(1-self.beta_1**(self.counter+1))\n",
        "            rmsprop_correction = 1/(1-self.beta_2**(self.counter+1))\n",
        "\n",
        "            layer.V_corrected_dW = layer.V_dW*momentum_correction\n",
        "            layer.V_corrected_db = layer.V_db*momentum_correction\n",
        "            layer.S_corrected_dW = layer.S_dW*rmsprop_correction\n",
        "            layer.S_corrected_db = layer.S_db*rmsprop_correction\n",
        "        \n",
        "            layer.W = layer.W - self.learning_rate*(layer.V_corrected_dW/(np.sqrt(layer.S_corrected_dW)+self.epsilon))\n",
        "            layer.b = layer.b - self.learning_rate*(layer.V_corrected_db/(np.sqrt(layer.S_corrected_db)+self.epsilon))\n",
        "        self.counter += 1\n",
        "        return True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDF-qxOkDRkC"
      },
      "source": [
        "### Mechanic Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AtYLk9GDRkD"
      },
      "source": [
        "class MechanicRules(Optimizer):\n",
        "    def __init__(self, learning_rate, g=9.81):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.g = g\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.v_hat_W = np.zeros(layer.W.shape)\n",
        "            layer.v_hat_b = np.zeros(layer.b.shape)\n",
        "            \n",
        "            layer.a_hat_W = np.zeros(layer.W.shape)\n",
        "            layer.a_hat_b = np.zeros(layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            s_W = 1 / (np.sqrt(1+np.square(layer.dW))+self.epsilon)\n",
        "            s_b = 1 / (np.sqrt(1+np.square(layer.db))+self.epsilon)\n",
        "            \n",
        "            layer.W = (-0.5*(self.g*layer.dW*s_W + layer.a_hat_W)*(self.learning_rate**2) + layer.v_hat_W*self.learning_rate + layer.W)*s_W\n",
        "            layer.b = (-0.5*(self.g*layer.db*s_b + layer.a_hat_b)*(self.learning_rate**2) + layer.v_hat_b*self.learning_rate + layer.b)*s_b\n",
        "            \n",
        "            layer.v_hat_W = -(self.g*layer.dW*s_W+layer.a_hat_W)*self.learning_rate + layer.v_hat_W\n",
        "            layer.v_hat_b = -(self.g*layer.db*s_b+layer.a_hat_b)*self.learning_rate + layer.v_hat_b\n",
        "        return True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyD3j-T1DRkJ"
      },
      "source": [
        "### Gravity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8wmeEOcDRkK"
      },
      "source": [
        "class Gravity(Optimizer):\n",
        "    def __init__(self, learning_rate, g=9.81):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.g = -g\n",
        "        self.epsilon = 1e-8\n",
        "        self.update_counter = 0\n",
        "        self.learning_rate_history = {0: learning_rate}\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.v_W = np.zeros(layer.W.shape)\n",
        "            layer.v_b = np.zeros(layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            c_W = layer.dW / (1+np.square(layer.dW)+self.epsilon)            \n",
        "            layer.v_W = self.g*c_W*self.learning_rate + layer.v_W\n",
        "            c_b = layer.db / (1+np.square(layer.db)+self.epsilon)\n",
        "            layer.v_b = self.g*c_b*self.learning_rate + layer.v_b  \n",
        "            \n",
        "            layer.W = self.learning_rate*layer.v_W + layer.W\n",
        "            layer.b = self.learning_rate*layer.v_b + layer.b\n",
        "            self.update_counter += 1\n",
        "        return True\n",
        "    def update_optimizer(self, metrics: dict):\n",
        "        metrics['learning_rate'].append(self.learning_rate)\n",
        "        metrics['g'].append(self.g)\n",
        "        return metrics\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaJWMYCtVkj"
      },
      "source": [
        "class Gravity2(Optimizer):\n",
        "    def __init__(self, learning_rate, g=9.81):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.g = -g\n",
        "        self.epsilon = 1e-8\n",
        "        self.update_counter = 0\n",
        "        self.learning_rate_history = {0: learning_rate}\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.v_W = np.zeros(layer.W.shape)\n",
        "            layer.v_b = np.zeros(layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            c_W = layer.dW / (1+np.square(layer.dW)+self.epsilon)\n",
        "            v_W_correct = np.where(layer.dW>0, -1, 1)*np.absolute(layer.v_W)         \n",
        "            layer.v_W = self.g*c_W*self.learning_rate + v_W_correct\n",
        "\n",
        "            c_b = layer.db / (1+np.square(layer.db)+self.epsilon)\n",
        "            v_b_correct = np.where(layer.db>0, -1, 1)*np.absolute(layer.v_b)\n",
        "            layer.v_b = self.g*c_b*self.learning_rate + v_b_correct\n",
        "            \n",
        "            layer.W = self.learning_rate*layer.v_W + layer.W\n",
        "            layer.b = self.learning_rate*layer.v_b + layer.b\n",
        "            self.update_counter += 1\n",
        "        return True\n",
        "    def update_optimizer(self, metrics: dict):\n",
        "        pass\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOJfPDKUv58E"
      },
      "source": [
        "class Gravity3(Optimizer):\n",
        "    def __init__(self, learning_rate, beta=0.9, g=10):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = beta\n",
        "        self.epsilon = 1e-8\n",
        "        self.g=g\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.v_W = np.zeros(layer.W.shape)\n",
        "            layer.v_b = np.zeros(layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            c_W = layer.dW / (1+np.square(layer.dW)+self.epsilon)\n",
        "            v_W_correct = np.where(layer.dW>0, -1, 1)*np.absolute(layer.v_W)         \n",
        "            layer.v_W = -self.beta*c_W*self.g*self.learning_rate + (1-self.beta)*v_W_correct\n",
        "\n",
        "            c_b = layer.db / (1+np.square(layer.db)+self.epsilon)\n",
        "            v_b_correct = np.where(layer.db>0, -1, 1)*np.absolute(layer.v_b)\n",
        "            layer.v_b = -self.beta*c_b*self.g*self.learning_rate + (1-self.beta)*v_b_correct\n",
        "            \n",
        "            layer.W = self.learning_rate*layer.v_W + layer.W\n",
        "            layer.b = self.learning_rate*layer.v_b + layer.b\n",
        "        return True\n",
        "    def update_optimizer(self, metrics: dict):\n",
        "        pass\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B345P8vMe_yH"
      },
      "source": [
        "### Courant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e61Fr2_e9xZ"
      },
      "source": [
        "class Courant(Optimizer):\n",
        "    def __init__(self, g=9.81, courant_max=0.01, sine_mode=False, mu=0):\n",
        "        self.g = -g\n",
        "        self.epsilon = 1e-8\n",
        "        self.update_counter = 0\n",
        "        self.courant_max = courant_max\n",
        "        self.sine_mode = 1 if sine_mode else 0\n",
        "        self.mu = mu\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.v_W = np.zeros(layer.W.shape)\n",
        "            layer.v_b = np.zeros(layer.b.shape)\n",
        "            layer.dt_W = np.random.rand(*layer.W.shape)\n",
        "            layer.dt_b = np.random.rand(*layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            c_W = (layer.dW-self.mu) / (1+np.square(layer.dW)+self.epsilon)            \n",
        "            layer.v_W = self.g*c_W* layer.dt_W + layer.v_W\n",
        "            dx_W_num = np.absolute(layer.dW)**self.sine_mode\n",
        "            dx_W_denom = np.sqrt(1+np.square(layer.dW) + self.epsilon)\n",
        "            dx_W = dx_W_num/dx_W_denom\n",
        "            layer.dt_W = (self.courant_max*dx_W) / (np.absolute(layer.v_W)+self.epsilon)\n",
        "\n",
        "            c_b = (layer.db-self.mu) / (1+np.square(layer.db)+self.epsilon)            \n",
        "            layer.v_b = self.g*c_b* layer.dt_b + layer.v_b\n",
        "            dx_b_num = np.absolute(layer.db)**self.sine_mode\n",
        "            dx_b_denom = np.sqrt(1+np.square(layer.db) + self.epsilon)\n",
        "            dx_b = dx_b_num / dx_b_denom\n",
        "            layer.dt_b = (self.courant_max*dx_b) / (np.absolute(layer.v_b)+self.epsilon) \n",
        "            \n",
        "            layer.W = layer.dt_W*layer.v_W + layer.W\n",
        "            layer.b = layer.dt_b*layer.v_b + layer.b\n",
        "            self.update_counter += 1\n",
        "        return True\n",
        "    def update_optimizer(self, metrics: dict):\n",
        "        pass"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJiUq-HYOX0A"
      },
      "source": [
        "class Courant2(Optimizer):\n",
        "    def __init__(self, beta=0.9, courant_max=0.01, sine_mode=False, mu=0):\n",
        "        self.beta = beta\n",
        "        self.epsilon = 1e-8\n",
        "        self.update_counter = 0\n",
        "        self.courant_max = courant_max\n",
        "        self.sine_mode = 1 if sine_mode else 0\n",
        "        self.mu = mu\n",
        "\n",
        "    def initiate_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            layer.v_W = np.zeros(layer.W.shape)\n",
        "            layer.v_b = np.zeros(layer.b.shape)\n",
        "            layer.dt_W = np.random.rand(*layer.W.shape)\n",
        "            layer.dt_b = np.random.rand(*layer.b.shape)\n",
        "        return True\n",
        "            \n",
        "    def update_parameters(self, layers: list):\n",
        "        for layer in layers:\n",
        "            c_W = (layer.dW-self.mu) / (1+np.square(layer.dW)+self.epsilon)\n",
        "            v_W_correct = np.where(layer.dW>0, -1, 1)*np.absolute(layer.v_W)   \n",
        "            layer.v_W = -self.beta*c_W* layer.dt_W + (1-self.beta)*v_W_correct\n",
        "            dx_W_num = np.absolute(layer.dW)**self.sine_mode\n",
        "            dx_W_denom = np.sqrt(1+np.square(layer.dW) + self.epsilon)\n",
        "            dx_W = dx_W_num/dx_W_denom\n",
        "            layer.dt_W = (self.courant_max*dx_W) / (np.absolute(layer.v_W)+self.epsilon)\n",
        "\n",
        "            c_b = (layer.db-self.mu) / (1+np.square(layer.db)+self.epsilon)\n",
        "            v_b_correct = np.where(layer.db>0, -1, 1)*np.absolute(layer.v_b)          \n",
        "            layer.v_b = -self.beta*c_b* layer.dt_b + (1-self.beta)*v_b_correct\n",
        "            dx_b_num = np.absolute(layer.db)**self.sine_mode\n",
        "            dx_b_denom = np.sqrt(1+np.square(layer.db) + self.epsilon)\n",
        "            dx_b = dx_b_num / dx_b_denom\n",
        "            layer.dt_b = (self.courant_max*dx_b) / (np.absolute(layer.v_b)+self.epsilon) \n",
        "            \n",
        "            layer.W = layer.dt_W*layer.v_W + layer.W\n",
        "            layer.b = layer.dt_b*layer.v_b + layer.b\n",
        "            self.update_counter += 1\n",
        "        return True\n",
        "    def update_optimizer(self, metrics: dict):\n",
        "        pass"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kArP_ESqtvYG"
      },
      "source": [
        "## Main Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVvWPqcotvYO"
      },
      "source": [
        "class Classifier(object):\n",
        "    def __init__(self, model_structure: ModelStructure, binary=False):\n",
        "        self.input_features = model_structure.layers[0].units_number\n",
        "        self.layers = initialize(model_structure.layers)\n",
        "        self.layers_backup = copy.deepcopy(self.layers)\n",
        "        self.cost_function = get_cross_entropy_cost_function(binary=binary)[0]\n",
        "        self.cost_function_derivative = get_cross_entropy_cost_function(binary=binary)[1]\n",
        "        self.accuracy_func = get_accuracy_function(binary=binary)\n",
        "        self.predict_function = get_predict_function(apply_softmax=not binary)\n",
        "        self.metrics = {\n",
        "                        'costs': [],\n",
        "                        'accuracies': [],\n",
        "                        'validation_costs': [],\n",
        "                        'validation_accuracies': [],\n",
        "                        'total_trained_epochs': 0,\n",
        "                        'current_trained_epochs': 0,\n",
        "                        }\n",
        "\n",
        "    def undo_update(self):\n",
        "        self.layers = copy.deepcopy(self.layers_backup)\n",
        "        self.metrics['costs'].pop()\n",
        "        self.metrics['accuracies'].pop()\n",
        "        self.metrics['validation_costs'].pop()\n",
        "        self.metrics['validation_accuracies'].pop()\n",
        "        self.metrics['total_trained_epochs'] -= 1\n",
        "        self.metrics['current_trained_epochs'] -= 1\n",
        "        print('Last Successful Parameters Recovered')\n",
        "\n",
        "    def feed_forward(self, X: np.ndarray):\n",
        "        assert X.shape[0] == self.input_features\n",
        "        A_prev = X\n",
        "        for layer in self.layers:\n",
        "            Z = np.dot(layer.W, A_prev) + layer.b\n",
        "            A = layer.activation_function(Z)\n",
        "            A_prev = A\n",
        "        Y_hat = A_prev\n",
        "        return Y_hat\n",
        "\n",
        "    def feed_forward_train(self, X: np.ndarray):\n",
        "        assert X.shape[0] == self.input_features\n",
        "        A_prev = X\n",
        "        for layer in self.layers:\n",
        "            layer.A_previous = A_prev\n",
        "            layer.Z = np.dot(layer.W, A_prev) + layer.b\n",
        "            A_raw = layer.activation_function(\n",
        "                layer.Z)  # Before applying dropout\n",
        "            layer.D = np.random.rand(\n",
        "                *A_raw.shape) < layer.keep_prob  # Dropout Mask\n",
        "            layer.A = (A_raw * layer.D) / layer.keep_prob\n",
        "            A_prev = layer.A\n",
        "        Y_hat = A_prev\n",
        "        return Y_hat\n",
        "\n",
        "    def back_propagate(self, cost_derivative, lambda_):\n",
        "        dA_prev = cost_derivative\n",
        "        m = self.layers[0].Z.shape[1]  # number of examples\n",
        "        for layer in self.layers[::-1]:\n",
        "            layer.dA = (dA_prev*layer.D) / layer.keep_prob\n",
        "            layer.dZ = layer.dA * layer.activation_function_derivative(layer.Z)\n",
        "            layer.dW = (1/m) * np.dot(layer.dZ,\n",
        "                                      layer.A_previous.T) + (lambda_/m)*layer.W\n",
        "            layer.db = 1/m * np.sum(layer.dZ, axis=1, keepdims=True)\n",
        "            dA_prev = np.dot(layer.W.T, layer.dZ)\n",
        "        return True\n",
        "\n",
        "    def fit_minibatch(self, mini_X, mini_Y, lambda_, optimizer):\n",
        "        mini_Y_hat = self.feed_forward_train(mini_X)\n",
        "        cost_derivative = self.cost_function_derivative(mini_Y, mini_Y_hat)\n",
        "        self.back_propagate(cost_derivative, lambda_)\n",
        "        optimizer.update_parameters(self.layers)\n",
        "        return True\n",
        "\n",
        "    def fit(self, X, Y, epochs, batch_size, optimizer,\n",
        "            lambda_=0,\n",
        "            validation_data=None,\n",
        "            metrics_printer=None):\n",
        "        \n",
        "        # Assert Shapes\n",
        "        assert X.shape[1] == Y.shape[1]        \n",
        "        m = X.shape[1]\n",
        "        if validation_data:\n",
        "            assert type(validation_data) == tuple\n",
        "            assert type(validation_data[0]) == np.ndarray\n",
        "            assert type(validation_data[1]) == np.ndarray\n",
        "            assert validation_data[0].shape[0] == X.shape[0]\n",
        "            assert validation_data[1].shape[0] == Y.shape[0]\n",
        "            assert validation_data[0].shape[1] == validation_data[1].shape[1]\n",
        "\n",
        "        self.metrics['current_trained_epochs'] = 0\n",
        "        optimizer.initiate_parameters(self.layers)\n",
        "        for _ in range(1, epochs+1):\n",
        "            self.layers_backup = copy.deepcopy(self.layers)           \n",
        "            mini_batchs = mini_batch_generator(X, Y, batch_size)\n",
        "            for mini_X, mini_Y in mini_batchs:\n",
        "                self.fit_minibatch(mini_X, mini_Y, lambda_, optimizer)\n",
        "\n",
        "            regularization_cost = get_regularization_cost(self.layers, m,\n",
        "                                                          lambda_)\n",
        "\n",
        "            train_Y_hat = self.feed_forward(X)\n",
        "            train_cost = self.cost_function(Y, train_Y_hat)\n",
        "            train_cost += regularization_cost\n",
        "            train_prediction = self.predict_function(train_Y_hat)\n",
        "            train_accuracy = self.accuracy_func(train_prediction, Y)\n",
        "            self.metrics['costs'].append(train_cost)\n",
        "            self.metrics['accuracies'].append(train_accuracy)\n",
        "\n",
        "            if validation_data:\n",
        "                validation_X = validation_data[0]\n",
        "                validation_Y = validation_data[1]\n",
        "                validation_Y_hat = self.feed_forward(validation_X)\n",
        "                validation_cost = self.cost_function(validation_Y,\n",
        "                                                     validation_Y_hat) \n",
        "                validation_cost += regularization_cost\n",
        "                validation_prediction = self.predict_function(validation_Y_hat)\n",
        "                validation_accuracy = self.accuracy_func(validation_prediction,\n",
        "                                                         validation_Y)\n",
        "                self.metrics['validation_costs'].append(validation_cost)\n",
        "                self.metrics['validation_accuracies'].append(validation_accuracy)\n",
        "\n",
        "            self.metrics['total_trained_epochs'] += 1\n",
        "            self.metrics['current_trained_epochs'] += 1\n",
        "\n",
        "            if metrics_printer:\n",
        "                metrics_printer(self.metrics)\n",
        "                         \n",
        "            optimizer.update_optimizer(self.metrics)            \n",
        "        return self.metrics"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNMSqla9L9PF"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BRPI1CUL9PG"
      },
      "source": [
        "def get_dataset(dataset_path):\n",
        "    data = np.load(dataset_path)\n",
        "    X_train = data['X_train']\n",
        "    Y_train = data['Y_train']\n",
        "    X_test = data['X_test']\n",
        "    Y_test = data['Y_test']\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IbnZyMtL9PM"
      },
      "source": [
        "def one_hot_encode(Y, C):\n",
        "    assert Y.ndim == 1\n",
        "    m = Y.shape[0]\n",
        "    shape = (C, m)\n",
        "    result = np.zeros(shape)\n",
        "    result[Y,np.arange(m)] = 1\n",
        "    return result"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucWtk2EqL9PT"
      },
      "source": [
        "mnist_path = Path.joinpath(Path('datasets'), Path('mnist.npz'))\n",
        "X_train, Y_train, X_test, Y_test = get_dataset(mnist_path)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kmvxa0ZL9Pb"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], -1).T\n",
        "X_test = X_test.reshape(X_test.shape[0], -1).T\n",
        "Y_train = one_hot_encode(Y_train, 10)\n",
        "Y_test = one_hot_encode(Y_test, 10)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slwXNv9bL9Pu",
        "outputId": "5baaa8c1-7cf0-433d-efe3-a0e88b1b59d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "index = 85\n",
        "print(Y_train[:,index])\n",
        "PIL.Image.fromarray(X_train[:, index].reshape(28, 28)).resize((200, 200))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F400B93DDA0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbM5Vhi8L9P5"
      },
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdJ3ca4hL9P-",
        "outputId": "8f27581a-8546-428b-844c-85afebf72d3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "structure = ModelStructure()\n",
        "structure.add_input_layer(X_train.shape[0])\n",
        "structure.add_layer(128, 'relu', keep_prob=0.8)\n",
        "structure.add_layer(10)\n",
        "structure.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Features: 784\n",
            "Layer #1: 128 relu units with 100352 weights and 128 biases\n",
            "Layer #2: 10 identity units with 1280 weights and 10 biases\n",
            "Total Parameters: 101770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ma_VV8lL9QF"
      },
      "source": [
        "try:\n",
        "    del model\n",
        "except NameError:\n",
        "    pass\n",
        "model = Classifier(structure)\n",
        "\n",
        "gd_optimizer = GradientDescent(learning_rate=0.01)\n",
        "\n",
        "momentum_optimizer = Momentum(learning_rate=0.001, beta=0.9)\n",
        "rmsprop_optimizer = RMSprop(learning_rate=0.0002, beta=0.999)\n",
        "adam_optimizer = Adam(learning_rate=0.0001)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6qtaqfO7CKe",
        "outputId": "66b5b40e-60f0-4511-b1db-940b23fff015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "adam_optimizer = Adam(learning_rate=0.001)\n",
        "epochs=5\n",
        "metrics = model.fit(X_train, Y_train, epochs, optimizer=adam_optimizer,\n",
        "                    batch_size=32, validation_data=(X_test, Y_test),\n",
        "                    lambda_=0, metrics_printer=print_metrics(1))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0001 | Cost: 0.1553 | Accuracy: 94.53% | Validation Cost: 0.1586 | Validation Accuracy: 94.40%\n",
            "Epoch #0002 | Cost: 0.1102 | Accuracy: 96.34% | Validation Cost: 0.0997 | Validation Accuracy: 96.60%\n",
            "Epoch #0003 | Cost: 0.2181 | Accuracy: 91.94% | Validation Cost: 0.1618 | Validation Accuracy: 94.62%\n",
            "Epoch #0004 | Cost: 9.2102 | Accuracy: 9.87% | Validation Cost: 9.2103 | Validation Accuracy: 9.80%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-468828e35118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m metrics = model.fit(X_train, Y_train, epochs, optimizer=adam_optimizer,\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     lambda_=0, metrics_printer=print_metrics(1))\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-9ca57f357b98>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, epochs, batch_size, optimizer, lambda_, validation_data, metrics_printer)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmini_batchs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmini_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_Y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batchs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             regularization_cost = get_regularization_cost(self.layers, m,\n",
            "\u001b[0;32m<ipython-input-23-9ca57f357b98>\u001b[0m in \u001b[0;36mfit_minibatch\u001b[0;34m(self, mini_X, mini_Y, lambda_, optimizer)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mmini_Y_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mcost_derivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_Y_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_derivative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-9ca57f357b98>\u001b[0m in \u001b[0;36mfeed_forward_train\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_previous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             A_raw = layer.activation_function(\n\u001b[1;32m     46\u001b[0m                 layer.Z)  # Before applying dropout\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otx1AgjQwP3W",
        "outputId": "40b04d79-8b63-4c7a-f088-d81a43eb63e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "gravity3 = Gravity3(learning_rate=0.5, beta=0.999, g=1)\n",
        "epochs=1000\n",
        "metrics = model.fit(X_train, Y_train, epochs, optimizer=gravity3,\n",
        "                    batch_size=512, validation_data=(X_test, Y_test),\n",
        "                    lambda_=0, metrics_printer=print_metrics(1))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #0001 | Cost: 0.3581 | Accuracy: 86.32% | Validation Cost: 0.3445 | Validation Accuracy: 86.67%\n",
            "Epoch #0002 | Cost: 0.2597 | Accuracy: 90.61% | Validation Cost: 0.2519 | Validation Accuracy: 90.87%\n",
            "Epoch #0003 | Cost: 0.2324 | Accuracy: 91.73% | Validation Cost: 0.2249 | Validation Accuracy: 91.94%\n",
            "Epoch #0004 | Cost: 0.2034 | Accuracy: 92.81% | Validation Cost: 0.1997 | Validation Accuracy: 93.04%\n",
            "Epoch #0005 | Cost: 0.1801 | Accuracy: 93.69% | Validation Cost: 0.1815 | Validation Accuracy: 93.72%\n",
            "Epoch #0006 | Cost: 0.1632 | Accuracy: 94.26% | Validation Cost: 0.1627 | Validation Accuracy: 94.28%\n",
            "Epoch #0007 | Cost: 0.1539 | Accuracy: 94.69% | Validation Cost: 0.1517 | Validation Accuracy: 94.75%\n",
            "Epoch #0008 | Cost: 0.1461 | Accuracy: 94.99% | Validation Cost: 0.1471 | Validation Accuracy: 95.04%\n",
            "Epoch #0009 | Cost: 9.2103 | Accuracy: 9.87% | Validation Cost: 9.2103 | Validation Accuracy: 9.80%\n",
            "Epoch #0010 | Cost: 9.2103 | Accuracy: 9.87% | Validation Cost: 9.2103 | Validation Accuracy: 9.80%\n",
            "Epoch #0011 | Cost: 9.2103 | Accuracy: 9.87% | Validation Cost: 9.2103 | Validation Accuracy: 9.80%\n",
            "Epoch #0012 | Cost: 9.2103 | Accuracy: 9.87% | Validation Cost: 9.2103 | Validation Accuracy: 9.80%\n",
            "Epoch #0013 | Cost: 9.2103 | Accuracy: 9.87% | Validation Cost: 9.2103 | Validation Accuracy: 9.80%\n",
            "Epoch #0014 | Cost: 9.2103 | Accuracy: 9.87% | Validation Cost: 9.2103 | Validation Accuracy: 9.80%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-0c1e9894e82f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m metrics = model.fit(X_train, Y_train, epochs, optimizer=gravity3,\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     lambda_=0, metrics_printer=print_metrics(1))\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-9ca57f357b98>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, epochs, batch_size, optimizer, lambda_, validation_data, metrics_printer)\u001b[0m\n\u001b[1;32m     98\u001b[0m                                                           lambda_)\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mtrain_Y_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mtrain_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtrain_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mregularization_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-9ca57f357b98>\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVqHpiKXt-Um"
      },
      "source": [
        "gravity2 = Gravity2(learning_rate=0.025, g=10)\n",
        "epochs=1\n",
        "metrics = model.fit(X_train, Y_train, epochs, optimizer=gravity2,\n",
        "                    batch_size=1024, validation_data=(X_test, Y_test),\n",
        "                    lambda_=0, metrics_printer=print_metrics(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h17rKyKBPM5m"
      },
      "source": [
        "courant_opt2 = Courant2(beta=0.9, courant_max=0.0001, sine_mode=True, mu=0)\n",
        "epochs=10\n",
        "metrics = model.fit(X_train, Y_train, epochs, optimizer=courant_opt2,\n",
        "                    batch_size=1024, validation_data=(X_test, Y_test), lambda_=0, metrics_printer=print_metrics(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEpB3EHBJP8M"
      },
      "source": [
        "model.undo_update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6kM2mBvhYbs"
      },
      "source": [
        "courant_opt = Courant(g=1, courant_max=0.01, sine_mode=True, mu=0)\n",
        "epochs=1\n",
        "metrics = model.fit(X_train, Y_train, epochs, optimizer=courant_opt,\n",
        "                    batch_size=512, validation_data=(X_test, Y_test), lambda_=0, metrics_printer=print_metrics(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A4LnpR-QMBA"
      },
      "source": [
        "gravity = Gravity(learning_rate=0.00001, g=10)\n",
        "epochs=100\n",
        "metrics = model.fit(X_train, Y_train, epochs, optimizer=gravity,\n",
        "                    batch_size=128, validation_data=(X_test, Y_test),\n",
        "                    lambda_=0, metrics_printer=print_metrics(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1fB0yPfL9QM"
      },
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "fig = plot_metrics(metrics, interval=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M6dW93ZL9QR"
      },
      "source": [
        "fig.savefig('mnist_32relu_100_gravity.png', dpi=300, transparent=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC2ZJ1QhL9Qb"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CRZT2TeL9Qg"
      },
      "source": [
        "\n",
        "with open('mnist_32relu_50_gravity_00005_10.model', 'wb') as fh:\n",
        "    pickle.dump(model, fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtvNlYahL9Qm"
      },
      "source": [
        "with open('mnist_32relu_50_gravity_00005_10.model', 'rb') as fh:\n",
        "    model_test = pickle.load(fh)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jABmmKLL9Qr",
        "outputId": "e2bc8ae0-47c4-4b2b-9055-c8a19bb5ac33"
      },
      "source": [
        "categorical_accuracy(predict(model_test.feed_forward(X_test)), Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-yiEWwkL9Qw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}